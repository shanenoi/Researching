# Transformers

_Basic Concept: Transformers is used to processing `Sequence Data` such as text, speech_

>`Transformers` can deal with the pros of `Recurrent Neural Networks` and `Long-Short Term Memory`
> + The problem of long-term dependencies
> + Can not apply parallel programming of GPU

_keyworks_:
 - Transformers [(1)](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
 - RNN [(1)](https://en.wikipedia.org/wiki/Recurrent_neural_network) [(2)](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)
 - LSTM [(1)](https://en.wikipedia.org/wiki/Long_short-term_memory)